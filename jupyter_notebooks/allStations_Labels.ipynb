{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Negin Sobhani, Jakidxav\n",
    "\n",
    "This Notebook is slightly different than the `ghcn_Import` Notebook, in that it creates hot and not-hot labels for the entire Eastern United States instead of one single station. We still subset for the right years and calendar days, and still compute an anomaly column for the maximum temperature for each station. However, instead of comparing one temperature to the cutoff value, we will compare whether all stations had greater than or equal to the mean + 1 standard deviation temperature anomalies across days and stations. In this way, we can create labels that account for every station in the Eastern US at the same time.\n",
    "\n",
    "As in the last Notebook, we can still create the training, development, and validation set labels at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avotbVG7g2y0"
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0gZVgKCg2zG"
   },
   "outputs": [],
   "source": [
    "ghcnd_csv_dir = '/glade/p/work/ddvento/ML/McKinnon_data/ghcnd/ghcnd_all_csv/'\n",
    "        \n",
    "#starting and end years for loading in data\n",
    "start_year = 1982\n",
    "end_year   = 2015\n",
    "\n",
    "#the days we care about; specified in mckinnon's paper\n",
    "start_doy  = 175\n",
    "end_doy    = 234\n",
    "  \n",
    "#cutoff for choosing whether the day was anomalously hot or not\n",
    "cut_off = 6.5\n",
    "count = 0\n",
    "\n",
    "#dev/test set include 2 el nino years, 1 non-el nino years\n",
    "#https://www.esrl.noaa.gov/psd/enso/past_events.html\n",
    "dev_nino_list = [1983, 1990, 1995, 2008]\n",
    "val_nino_list = [1988, 1994, 1999, 2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHK8lycVg2zR"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "get_ghcnd_stn:\n",
    "    *Opens the csv file for the GHCND station as df\n",
    "    *Add a pd.datetime column to the df\n",
    "    *Add Julian Day (day of the year) jday to the df \n",
    "    *Selects data for only the training years\n",
    "    *Selects data for only the selected days of a year ( e.g. 60 days of summer.) \n",
    "\n",
    "----------\n",
    "Parameters:\n",
    "    ghcnd_csv_dir --- path to GHCN processed csv files.\n",
    "    stn_id --- GHCN station ID based on GHCN readme.txt\n",
    "        (ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt)\n",
    "\n",
    "    start_year --- start year for the period to slice. \n",
    "    end_year \n",
    "\n",
    "    start_doy  --- start julian day (day of year) for the period\n",
    "                    you are looking at.  \n",
    "    end_doy\n",
    "-------\n",
    "Returns:\n",
    "    stn_data --- \n",
    "\n",
    "-------\n",
    "Example:\n",
    "    stn_data = get_ghcnd_stn(ghcnd_csv_dir,stn_id,1982,\n",
    "                2015, 30, 90)\n",
    "\n",
    "'''\n",
    "def get_ghcnd_stn (ghcnd_csv_dir, stn_id, start_year, end_year, start_doy, end_doy):\n",
    "        #create station label so that we can read in the file using pandas\n",
    "        stn_csv = ghcnd_csv_dir+stn_id+'.csv'\n",
    "        \n",
    "        #read in file, replace nan values\n",
    "        stn_raw = pd.read_csv(stn_csv,na_values=-9999)\n",
    "            \n",
    "        #convert dates into datetime objects so that we can extract the day of the year\n",
    "        stn_raw['date']=pd.to_datetime(stn_raw['YYYY'].astype(str)+'-'+stn_raw['MM'].astype(str)+'-'+stn_raw['DD'].astype(str))\n",
    "        stn_raw['jday'] = stn_raw['date'].dt.dayofyear.apply(lambda x: str(x).zfill(3)).astype(int)\n",
    "\n",
    "        #subset data based on years and calendar days\n",
    "        yrs_data = stn_raw[(stn_raw['YYYY']>=start_year) & (stn_raw['YYYY']<=end_year)]\n",
    "        stn_data= yrs_data[(yrs_data['jday']>=start_doy) & (yrs_data['jday']<=end_doy)]\n",
    "            \n",
    "        return stn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Fxc33AOg2zg"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "calc_stn_anom :\n",
    "    *Calculates the anomalies of selected var for the station.\n",
    "----------\n",
    "Parameters:\n",
    "    stn_data ---\n",
    "    var --- Name of the varibale to calculate anomalies on :\n",
    "            e.g. TMAX, TMIN, PRCP\n",
    "-------\n",
    "Returns:\n",
    "    stn_data --- \n",
    "\n",
    "-------\n",
    "Example:\n",
    "    calc_stn_anom (stn_data, 'TMAX')\n",
    "    '''\n",
    "def calc_stn_anom (stn_data, var):\n",
    "        #create an anomaly column variable in our dataframe\n",
    "        var_anom= var+\"ANOM\"\n",
    "        \n",
    "        #create mean of a given variable by the .groupby() method and applying a mean transform\n",
    "        means=stn_data.groupby(['MM','DD'])[var].transform('mean')\n",
    "            \n",
    "        #create anomaly by subtracting mean\n",
    "        stn_data[var_anom]= stn_data[var] - means\n",
    "            \n",
    "        return stn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33T9chMZg2zt"
   },
   "outputs": [],
   "source": [
    "#picked this station because I know it has full 2040 values\n",
    "#thus multi-index will have correct dimensions for concatenation\n",
    "station_data = get_ghcnd_stn(ghcnd_csv_dir, 'USC00391621', start_year, end_year, start_doy, end_doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_ACdlCAg20E",
    "outputId": "024b2563-8990-47cb-d432-d5c47d9faa44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TMAXANOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYY</th>\n",
       "      <th>jday</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1982</th>\n",
       "      <th>175</th>\n",
       "      <td>2.938235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-8.567647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-6.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.920588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2.338235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TMAXANOM\n",
       "YYYY jday          \n",
       "1982 175   2.938235\n",
       "     176  -8.567647\n",
       "     177  -6.014706\n",
       "     178  -1.920588\n",
       "     179   2.338235"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the station anomaly for the maximum temperature variable\n",
    "station_data = calc_stn_anom(station_data, 'TMAX')\n",
    "\n",
    "#drop every column except for the anomaly column\n",
    "station_data.drop(['MM', 'DD', 'PRCP', 'SNOW', 'SNWD', 'date', 'TMIN', 'TMAX'], axis=1, inplace=True)\n",
    "\n",
    "#set the index to be the year and the calendar day\n",
    "station_data.set_index(['YYYY','jday'], inplace=True)\n",
    "station_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjQrZh6og20m"
   },
   "outputs": [],
   "source": [
    "#here we can load in another station, and complete the same steps as we did for `station_data`\n",
    "station_data2 = get_ghcnd_stn(ghcnd_csv_dir, 'USC00393832', start_year, end_year, start_doy, end_doy)\n",
    "station_data2 = calc_stn_anom(station_data2, 'TMAX')\n",
    "station_data2.drop(['MM', 'DD', 'PRCP', 'SNOW', 'SNWD', 'date', 'TMIN', 'TMAX'], axis=1, inplace=True)\n",
    "station_data2.set_index(['YYYY','jday'], inplace=True)\n",
    "\n",
    "#then we can concatenate the two stations together\n",
    "big_station = pd.concat([station_data, station_data2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dsdih_6Tg21M",
    "outputId": "ee6b3cc5-f256-4427-9b4a-4a6282902688"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TMAXANOM</th>\n",
       "      <th>TMAXANOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYY</th>\n",
       "      <th>jday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1982</th>\n",
       "      <th>175</th>\n",
       "      <td>2.938235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-8.567647</td>\n",
       "      <td>-6.335484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-6.014706</td>\n",
       "      <td>-1.025806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.920588</td>\n",
       "      <td>2.165625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2.338235</td>\n",
       "      <td>5.320690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TMAXANOM  TMAXANOM\n",
       "YYYY jday                    \n",
       "1982 175   2.938235       NaN\n",
       "     176  -8.567647 -6.335484\n",
       "     177  -6.014706 -1.025806\n",
       "     178  -1.920588  2.165625\n",
       "     179   2.338235  5.320690"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! That worked. So now we can load in all of the other stations in our directory and perform the same steps. We are doing this to create a single label for every station in our data set. Thus, we will be predicting whether the entire Eastern US is anomalously hot instead of one specific station.\n",
    "\n",
    "McKinnon also does this in her paper. Because of the variablility in prediction skill between stations, we can create a new label to represent all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvnmqrLjg21z"
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(ghcnd_csv_dir):\n",
    "    if(np.logical_and(file != 'USC00391621.csv', file != 'USC00393832.csv')):\n",
    "        count = count + 1\n",
    "        \n",
    "        stn_id = file.replace('.csv', '')\n",
    "        stn_data = get_ghcnd_stn(ghcnd_csv_dir, stn_id, start_year, end_year, start_doy, end_doy)\n",
    "        stn_data = calc_stn_anom(stn_data, 'TMAX')\n",
    "        stn_data.drop(['MM', 'DD', 'PRCP', 'SNOW', 'SNWD', 'date', 'TMIN', 'TMAX'], axis=1, inplace=True)\n",
    "        stn_data.set_index(['YYYY','jday'], inplace=True)\n",
    "        \n",
    "        big_station = pd.concat([big_station, stn_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ui9AUguyg23i"
   },
   "outputs": [],
   "source": [
    "#percentile across rows in dataframe\n",
    "#https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.quantile.html\n",
    "big_station['quant'] = big_station.quantile(0.95, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0cKI42Gg23x",
    "outputId": "0affcb78-f091-4131-9732-d9cc616e0329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYYY  jday\n",
      "1982  175     2.144848\n",
      "      176     1.551925\n",
      "      177     1.296279\n",
      "      178     2.184848\n",
      "      179     3.604355\n",
      "      180     3.942647\n",
      "      181     2.692197\n",
      "      182     1.912993\n",
      "      183     2.234941\n",
      "      184     4.854266\n",
      "      185     6.813182\n",
      "      186     7.101324\n",
      "      187     5.225680\n",
      "      188     4.017458\n",
      "      189     4.314706\n",
      "      190     3.437647\n",
      "      191     3.020588\n",
      "      192     3.142103\n",
      "      193     2.957059\n",
      "      194     3.234820\n",
      "      195     3.120321\n",
      "      196     3.372948\n",
      "      197     4.529661\n",
      "      198     4.708824\n",
      "      199     4.607353\n",
      "      200     4.626471\n",
      "      201     5.269091\n",
      "      202     4.824492\n",
      "      203     3.794875\n",
      "      204     3.625865\n",
      "                ...   \n",
      "2015  205     3.807241\n",
      "      206     4.186471\n",
      "      207     3.683323\n",
      "      208     4.261765\n",
      "      209     4.786765\n",
      "      210     5.146257\n",
      "      211     5.015931\n",
      "      212     3.776879\n",
      "      213     3.161858\n",
      "      214     3.413002\n",
      "      215     3.752121\n",
      "      216     3.387419\n",
      "      217     3.574171\n",
      "      218     3.588235\n",
      "      219     2.996533\n",
      "      220     3.381429\n",
      "      221     3.509980\n",
      "      222     3.763788\n",
      "      223     3.367462\n",
      "      224     3.927273\n",
      "      225     4.910660\n",
      "      226     5.792335\n",
      "      227     6.406765\n",
      "      228     5.492696\n",
      "      229     4.855882\n",
      "      230     5.065463\n",
      "      231     5.189924\n",
      "      232     4.581765\n",
      "      233     2.752941\n",
      "      234     2.243508\n",
      "Name: quant, Length: 2040, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(big_station.quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpVxMeQ4g24H",
    "outputId": "9e816bae-71b8-4116-be4a-956864579790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.262958844169827 2.0954880217628777\n"
     ]
    }
   ],
   "source": [
    "#calculate mean and standard deviation of the 95th percentile\n",
    "mean = big_station.quant.mean()\n",
    "stdev = big_station.quant.std()\n",
    "\n",
    "print(mean, stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBb3nDLUg24e"
   },
   "outputs": [],
   "source": [
    "#create a second label that is greater than the mean + 1 standard deviation in temperatures\n",
    "big_station['HOT2'] = np.where(big_station.quant >= mean+stdev, 1, 0)\n",
    "\n",
    "print(np.count_nonzero(big_station.HOT2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1dL8_blg257"
   },
   "outputs": [],
   "source": [
    "#reset our dataframe's index\n",
    "big_station.reset_index(inplace=True)\n",
    "\n",
    "#then create the development set like we did before\n",
    "#dev_nino_list = [1983, 1990, 1995, 2008]\n",
    "_1983 = big_station[big_station['YYYY'] == 1983]\n",
    "_1990 = big_station[big_station['YYYY'] == 1990]\n",
    "_1995 = big_station[big_station['YYYY'] == 1995]\n",
    "_2008 = big_station[big_station['YYYY'] == 2008]\n",
    "\n",
    "hot_dev = pd.concat([_1983, _1990, _1995, _2008])\n",
    "\n",
    "Y_dev = hot_dev.HOT2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeFU-IOKg261",
    "outputId": "53d38a79-c9df-4189-fbb2-a20222b5e1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8Jyymllg27A"
   },
   "outputs": [],
   "source": [
    "#same for the validation set\n",
    "#val_nino_list = [1988, 1994, 1999, 2003]\n",
    "_1988 = big_station[big_station.YYYY == 1988]\n",
    "_1994 = big_station[big_station.YYYY == 1994]\n",
    "_1999 = big_station[big_station.YYYY == 1999]\n",
    "_2003 = big_station[big_station.YYYY == 2003]\n",
    "\n",
    "hot_val = pd.concat([_1988, _1994, _1999, _2003])\n",
    "\n",
    "Y_val = hot_val.HOT2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuP073Nsg27Q",
    "outputId": "43a98b48-6441-4172-f8db-7d99ddbab5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05pisrrCg27b"
   },
   "outputs": [],
   "source": [
    "#and lastly our training set\n",
    "#for every year not in our dev or val sets, add it to the training set\n",
    "list_years = [1983, 1988, 1990, 1994, 1995, 1999, 2003, 2008]\n",
    "\n",
    "for i in list_years:\n",
    "    big_station = big_station[big_station.YYYY != i]\n",
    "    \n",
    "Y_train = big_station.HOT2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WE5KssPbg28B"
   },
   "outputs": [],
   "source": [
    "#make directories to save to if they aren't already there\n",
    "os.mkdir('/glade/work/jakidxav/IPython/20_lead/Y_train/station0/')\n",
    "os.mkdir('/glade/work/jakidxav/IPython/20_lead/Y_dev/station0/')\n",
    "os.mkdir('/glade/work/jakidxav/IPython/20_lead/Y_val/station0/')\n",
    "\n",
    "#then pickle the labels\n",
    "Y_train_filename = '/glade/work/jakidxav/IPython/20_lead/Y_train/station0/Y_train.txt'\n",
    "with open(Y_train_filename, 'wb') as f:\n",
    "    pickle.dump(Y_train, f)\n",
    "    \n",
    "Y_dev_filename = '/glade/work/jakidxav/IPython/20_lead/Y_dev/station0/Y_dev.txt'\n",
    "with open(Y_dev_filename, 'wb') as g:\n",
    "    pickle.dump(Y_dev, g)\n",
    "    \n",
    "Y_val_filename = '/glade/work/jakidxav/IPython/20_lead/Y_val/station0/Y_val.txt'\n",
    "with open(Y_val_filename, 'wb') as h:\n",
    "    pickle.dump(Y_val, h)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "allStations_Labels.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
